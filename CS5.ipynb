{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:\n",
    "##### Having imported the data, write code to study the following data characteristics:\n",
    "        a) number of rows and columns for the independent variables\n",
    "        b) labels of the columns for the independent variables and their meaning\n",
    "        c) target variable values and their meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for the independent variables: 20640\n",
      "Number of columns for the independent variables: 8\n",
      "\n",
      "Labels of the columns for the independent variables and their meaning:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "\n",
      "Target variable values and their meaning:\n",
      "   Target\n",
      "0   4.526\n",
      "1   3.585\n",
      "2   3.521\n",
      "3   3.413\n",
      "4   3.422\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Convert the dataset to a DataFrame\n",
    "df = pd.DataFrame(data=housing.data, columns=housing.feature_names)\n",
    "\n",
    "# a) Number of rows and columns for the independent variables\n",
    "num_rows, num_cols = df.shape\n",
    "print(\"Number of rows for the independent variables:\", num_rows)\n",
    "print(\"Number of columns for the independent variables:\", num_cols)\n",
    "\n",
    "# b) Labels of the columns for the independent variables and their meaning\n",
    "print(\"\\nLabels of the columns for the independent variables and their meaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# c) Target variable values and their meaning\n",
    "target = pd.DataFrame(data=housing.target, columns=['Target'])\n",
    "print(\"\\nTarget variable values and their meaning:\")\n",
    "print(target.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2:\n",
    "##### Write the code to train prediction models with a data split ratio 80/20 between training and test data. Your code should also consider reshuffling of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\"\"\"Note it should be fit on the training set only\"\"\"\n",
    "scaler = preprocessing.StandardScaler().fit(X_trn)\n",
    "\"\"\"Apply scaling parameters on both the training set and the validation set\"\"\"\n",
    "scaled_trnX = scaler.transform(X_trn)      \n",
    "scaled_valX = scaler.transform(X_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# Split the data into training and test sets with a ratio of 80/20 and shuffling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Now you can train your prediction models using X_train and y_train, and evaluate them on X_test and y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2:\n",
    "##### Having performed scaling for all values, you should develop the following regression models:\n",
    "        a) a Linear Regression model by displaying its intercept, trained coefficients, RMSE score as fitness metric.\n",
    "        b) a Stochastic Gradient Descent with Warm Restarts model, which is a variant of the stochastic gradient descent (SGD) optimisation algorithm commonly used in machine learning for training linear models, including linear regression models. You should display its intercept, trained coefficients, RMSE score as fitness metric. \n",
    "        b.1) For the model above, you should use 10 iterations as maximum and set both tol and eta, which are essential hyperparameters that need to be tuned carefully to achieve the desired balance between convergence speed and solution quality, as you think appropriate.\n",
    "        c) Prepare the data and develop a model of a higher degree polynomial, for instance, degree = 2. You should display its intercept, trained coefficients, RMSE score as fitness metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model:\n",
      "Intercept: 2.071946937378619\n",
      "Coefficients: [ 0.85438303  0.12254624 -0.29441013  0.33925949 -0.00230772 -0.0408291\n",
      " -0.89692888 -0.86984178]\n",
      "RMSE: 0.7455813830127763\n",
      "\n",
      "Stochastic Gradient Descent with Warm Restarts Model:\n",
      "Intercept: [2.06829884]\n",
      "Coefficients: [ 0.82409267  0.11960539 -0.25835617  0.30263456 -0.00337096 -0.01616009\n",
      " -0.96573075 -0.92032148]\n",
      "RMSE: 0.7432874102972927\n",
      "\n",
      "Higher Degree Polynomial Regression Model (Degree=2):\n",
      "Intercept: 1.956590491804071\n",
      "Coefficients: [ 1.31223617e-16  9.35940108e-01  1.32058017e-01 -3.87598691e-01\n",
      "  5.30206745e-01  4.05134644e-02 -1.78126342e+00 -1.27267893e+00\n",
      " -1.16762990e+00 -1.12225581e-01  3.78458372e-02  1.79781162e-01\n",
      " -1.20151603e-01  1.11429958e-01 -9.88397827e-02 -6.67216348e-01\n",
      " -5.86169281e-01  3.32914038e-02 -1.62467226e-02  5.23448500e-02\n",
      "  3.60251996e-02 -2.78667461e-01 -2.76779199e-01 -2.52812539e-01\n",
      "  6.04024501e-02 -1.09586039e-01 -1.54739809e-01  5.77923765e-01\n",
      "  5.43530824e-01  4.79070686e-01  4.95448185e-02  2.42099693e-01\n",
      " -4.01693105e-01 -4.88763320e-01 -4.22878296e-01  1.95177679e-03\n",
      "  3.23615260e-01  3.28004704e-02  1.52396884e-02  7.69437533e-03\n",
      "  5.06767490e-01  3.67138092e-01  2.63209600e-01  4.35127297e-01\n",
      "  1.53016171e-01]\n",
      "RMSE: 0.6813967448044703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# Split the data into training and test sets with a ratio of 80/20 and shuffling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# a) Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Linear Regression Model:\")\n",
    "print(\"Intercept:\", linear_model.intercept_)\n",
    "print(\"Coefficients:\", linear_model.coef_)\n",
    "y_pred_linear = linear_model.predict(X_test_scaled)\n",
    "rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear))\n",
    "print(\"RMSE:\", rmse_linear)\n",
    "\n",
    "# b) Stochastic Gradient Descent with Warm Restarts model\n",
    "sgd_model = SGDRegressor(max_iter=10, tol=1e-3, eta0=0.01)\n",
    "sgd_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nStochastic Gradient Descent with Warm Restarts Model:\")\n",
    "print(\"Intercept:\", sgd_model.intercept_)\n",
    "print(\"Coefficients:\", sgd_model.coef_)\n",
    "y_pred_sgd = sgd_model.predict(X_test_scaled)\n",
    "rmse_sgd = np.sqrt(mean_squared_error(y_test, y_pred_sgd))\n",
    "print(\"RMSE:\", rmse_sgd)\n",
    "\n",
    "# c) Higher degree polynomial model (degree=2)\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "poly_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nHigher Degree Polynomial Regression Model (Degree=2):\")\n",
    "print(\"Intercept:\", poly_model.named_steps['linearregression'].intercept_)\n",
    "print(\"Coefficients:\", poly_model.named_steps['linearregression'].coef_)\n",
    "y_pred_poly = poly_model.predict(X_test_scaled)\n",
    "rmse_poly = np.sqrt(mean_squared_error(y_test, y_pred_poly))\n",
    "print(\"RMSE:\", rmse_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
